[{"id":0,"href":"/Pipelines/Stages/","title":"Stages","parent":"Pipelines","content":"Pipeline Stages are logical groupings of Tasks to reflect the structure of the process, for example your process has a Build, Test and Release phase, the Pipeline Stages can be configured to reflect this.\n Pipeline Stages  Properties can be accessed from each stage and task using ${Stage.Task.Property} - for example, in the \u0026ldquo;Build\u0026rdquo; Stage the \u0026ldquo;Trigger Image Enumeration\u0026rdquo; task is a REST API call with a JSON response. The response property \u0026ldquo;id\u0026rdquo; is referenced using ${Build.Trigger Image Enumeration.output.responseBody.id}\n"},{"id":1,"href":"/Pipelines/Tasks/","title":"Tasks","parent":"Pipelines","content":"Code Stream Tasks are the basic units of a Pipeline, with different task types interacting with different systems.\nCommon configuration    Some configuration is common accross all task types\nPrecondition and Continue on failure    The precondition field can be used to determine if a Task should be executed - if the pre-condition evaluates to true the task will execute.\nFor example, if a task should only execute if a previous task completed successfully you can test the status of that task ${Stage0.task0.output.status} == \u0026quot;COMPLETED\u0026quot;\nIf Continue on failure is checked, the failure of this Task will not cause the entire Pipeline to fail. It can be combined with the precondition field to conditionally run subsequent tasks by checking the status of the failing task.  Common Task Configuration  Task Notifications    Task notifications are almost identical to Pipeline notifications except that they offer a specific events for the task (completes, is waiting, fails, starting).\n Task Notifications  Rollback    The Task Rollback setting allows you to configure a Pipeline that will be executed in the event that the Task fails. This can be used to clean up any artefacts generated by the Task execution that may be in an incomplete state. When you select the Rollback Pipeline you can configure the inputs for the selected pipeline, which would typically be variables from your parent (failing) Pipeline.\n Task Rollback  Available Task Types    More detailed information about each specific Task type is   Bamboo: This topic has not yet been documented on Learn Code Stream    CI    Condition   Custom   Kubernetes    Pipeline     Poll    PowerShell   REST   SSH   TFS   User Operation    VMware Cloud Template    vRealize Orchestrator    "},{"id":2,"href":"/Getting-Started/","title":"Getting Started","parent":"","content":""},{"id":3,"href":"/Dashboards/","title":"Dashboards","parent":"","content":"Code Stream users can view Dashboards to review historic data for any and all pipelines executions.\nIn addition to the automatically generated default dashboards, Custom Dashboards can be created by developers and administrators to view specific results by adding widgets from the menu to display statistics.\n   "},{"id":4,"href":"/Executions/","title":"Executions","parent":"","content":"In Executions, youâ€™ll find a detailed account of every pipeline execution that can be filtered by Pipeline, Status, Tag - or any other property. You can view at a glance which pipelines have failed, where and the error messages returned.\n Pipeline Execution Overview  Clicking into an Execution will give you a detailed view of the Pipeline Stages, Tasks, Configuration, Inputs, Task Inputs, Task Outputs, Task execution logs, and the output JSON object from the execution. The Output JSON view is very useful for identifying variables from one task to pass to another - see Variables in Pipelines   Pipeline Execution Detail  It\u0026rsquo;s also worth noting that from the Pipelines view you can access the previous 5 executions directly, by clicking on the icons\n Pipeline Executions  "},{"id":5,"href":"/User-Operations/","title":"User Operations","parent":"","content":"To provide more granular management and governance of the DevOps timeline, User Operations can be configured to manage the continuation of the pipeline execution. When a pipeline is configured with an approval task, the pipeline is paused and queued for user interaction. These users can monitor approval tasks here on the User Operations tab.\nUntil a preconfigured user approves or rejects the pipeline task, the pipeline remains stopped. If the required user does not address the User Operation in the time allowed, the pipeline will expire.\n"},{"id":6,"href":"/Pipelines/","title":"Pipelines","parent":"","content":"A Pipeline is the primary mechanism for sequencing all the tasks that need to be performed, and is composed of one or more Stage, with one or more tasks in each stage.\nGeneral Pipeline Settings    The pipeline settings allow you to set the pipeline name, concurrency, description, icon and tags.Being able to change the concurrency of the pipeline is often useful if you\u0026rsquo;re using shared resources that either don\u0026rsquo;t have the capcity to host multiple running executions, or there are resources that cannot be shared   Pipeline general settings  Pipeline configuration    When editing a Pipeline there are four tabs to configure:\nWorkspace  The workspace tab configures the environment in which the pipeline runs\n Host specifies a Docker endpoint on which CI tasks and Custom Integrations will execute Builder image URL configures the container image that will be used for CI tasks or Custom Integrations. You can specify using the just an official image (e.g. python), the image and a tag (e.g. python:3.10.0a6-alpine) or a full URL (e.g. projects.registry.vmware.com/antrea/prom-prometheus:v2.19.3)The container image can be almost any image but it needs to have wget or curl in order to download and install the Code Stream CI Agent, which is installed when the container is spun up.    Image Registry selects the Docker Registry endpoint to use to pull the Builder image - if the registry requires credentials to pull an image you can specify them as part of the endpoint and those will be used. Working directory is the directory within a container image that will be used when running commands in a CI task - more often than not, you can leave this blank to default to /build Cache Environment Variables can be used to pass environment variables to a container (similar to the -e VAR_NAME=\u0026quot;value\u0026quot; flag in the docker run command) CPU limit if a CI task requires significant resources, the container\u0026rsquo;s allocated CPU can be increased - it\u0026rsquo;s not often required Memory limit if a CI task requires significant resources, container\u0026rsquo;s allocated Memory can be increased - it\u0026rsquo;s not often required Git clone - if the pipeline is triggered by a Git webhook, CI tasks will automatically clone the Git repository. Note: You will need to configure the pipeline Inputs with the Git auto-inject parameters for this to work!    Input   Model  The Model tab is where you configure the Stages and Tasks of the pipeline - it\u0026rsquo;s where you spend most of your time when creating and editing pipelines.\n A Stage is an encapsulation mechanism for tasks and are used for grouping the individual task execution statuses and results. A Task performs individual actions based on its type and configuration. Tasks can deploy VMware Cloud Templates, and perform actions on configured endpoints, or more generic tasks such as prompting for user interations with User Operation, polling a 3rd party data source with the Poll task, or even perform a REST call.   Output  Outputs can be mapped to values produced by tasks in a pipeline and can be useful when you\u0026rsquo;re nesting pipelines using the Pipeline task to return the results to the parent pipeline.\n  Variables in Pipelines    Most configurable fields within a Pipeline can also use [Variables], references to Input parameters, the output of other tasks or general pipeline properties by using a reference.\nThese can be accessed using by typing $, which will bring up the auto-completion:\n Reference auto-completion  Referring back to previous tasks is done using a heirarchy that matches the structure of the pipeline, for example: ${Build Stage.Build Task.output.exports.variableName} would refer to the value of a variable called variableName that was exported from a task called Build Task in the stage Build Stage.\nTasks return their output as JSON, and it\u0026rsquo;s often useful to look at a previously executed task to find the correct path to an output variable - if you look at the Execution of a Pipeline and examine the task details, you can click \u0026ldquo;View Output JSON\u0026rdquo; and use the \u0026ldquo;Path finder\u0026rdquo; option to discover the correct path: Notifications    The notifications tab allows you to configure notifications for pipeline events (completion, waiting for user interaction, failure, cancellation, and starting) using either an Email endpoint, Jira endpoint, or by creating a Webhook with a POST, PUT or PATCH payload.\nEmail   Pipeline Email Notifications   Ticket   Pipeline Jira Notifications   Webhook   Pipeline Webhook Notifications    More        Stages     Tasks    Bamboo: This topic has not yet been documented on Learn Code Stream    CI    Condition   Custom   Kubernetes    Pipeline     Poll    PowerShell   REST   SSH   TFS   User Operation    VMware Cloud Template    vRealize Orchestrator      Reference     Creating and using pipelines in vRealize Automation Code Stream  "},{"id":7,"href":"/Custom-Integrations/","title":"Custom Integrations","parent":"","content":"Custom Integrations allow you write custom code in Python, Shell or NodeJS, and execute your code as a Custom Task in a Stage of a Pipeline. When the Custom Integration task is executed, it uses the Docker Host endpoint and Container Image configured for the parent Pipeline.\nCreating a Custom Integration    The Custom Integration is essentially a YAML file with four sections:\n Runtime - defines the runtime for the Custom Integration (nodejs, python2, python3, shell) Code - this is a multi-line scalar (any indented text after the | symbol should be interpreted as a multi-line scalar value) of the code to execute Input Properties - an array of input properties that are used in the execution of the Code Output Properties - an array of output properties that are returned by the execution of the Code  Input Properties    The available input types are documented in article linked the reference section below, one of the easiest ways to understand the different types is to create a new Custom Integration, select the runtime of your choice, then view the generated placeholder content.\nShell  echo $inputPropertyName   Python  from context import getInput # Import the getInput function from context.py myInput = getInput(\u0026#34;inputPropertyName\u0026#34;)   NodeJS  var context = require(\u0026#34;./context.js\u0026#34;) // Import the getInput function from context.js var myInput = context.getInput(\u0026#34;inputPropertyName\u0026#34;);    Output Properties    Output properties are used to return values from the Custom Integration task - currently only one type (label) is supported. To return a value it should be out to the Output Property\nShell  export outputPropertyName = \u0026#34;outputPropertyValue\u0026#34;   Python  from context import setOutput # Import the setOutput function from context.py setOutput(\u0026#34;outputPropertyName\u0026#34;, \u0026#34;outputPropertyValue\u0026#34;)   NodeJS  var context = require(\u0026#34;./context.js\u0026#34;) // Import the setOutput function from context.js context.setOutput(\u0026#34;outputPropertyName\u0026#34;, \u0026#34;outputPropertyValue\u0026#34;);    Versioning and Releasing    When you create a new Custom Integration it will be created as a Draft. In order to use the Custom Integration in a Pipeline Task you must release a version - this means that the released version can\u0026rsquo;t be changed and cause the Pipeline to fail. When you create a Custom Task type in a Pipeline Stage you can select which version you wish to use.\n Version and release a Custom Integration  Example Custom Integration - Create a Basic Authentication Header    The below example code takes a username and password input and returns a basicAuthHeader output for each of the runtimes - it\u0026rsquo;s a very simple use case that helps me when working with a REST API that only accepts a basic authentication headers.\nShell  ---runtime:shellcode:| export basicAuthHeader=$(echo -n $username:$password | base64)inputProperties:# Username input- name:\u0026#39;username\u0026#39;type:texttitle:\u0026#39;Username\u0026#39;placeHolder:\u0026#39;Enter basic authentication usename\u0026#39;required:truebindable:true# Password input- name:\u0026#39;password\u0026#39;type:passwordtitle:\u0026#39;Password\u0026#39;placeHolder:\u0026#39;Enter basic authentication password\u0026#39;defaultValue:\u0026#39;\u0026#39;required:truebindable:trueoutputProperties:- name:basicAuthHeadertype:labeltitle:BasicAuthenticationHeader```  Python  ---runtime:\u0026#34;python3\u0026#34;code:| from base64 import b64encodefromcontextimportgetInput,setOutputusername=getInput(\u0026#39;username\u0026#39;)password=getInput(\u0026#39;password\u0026#39;)usernameAndPassword=b64encode(bytes(f\u0026#39;{username}:{password}\u0026#39;,encoding=\u0026#39;ascii\u0026#39;)).decode(\u0026#39;ascii\u0026#39;)setOutput(\u0026#39;basicAuthHeader\u0026#39;,\u0026#34;Basic \u0026#34;+usernameAndPassword)inputProperties:# Username input- name:\u0026#39;username\u0026#39;type:texttitle:\u0026#39;Username\u0026#39;placeHolder:\u0026#39;Enter basic authentication usename\u0026#39;required:truebindable:true# Password input- name:\u0026#39;password\u0026#39;type:passwordtitle:\u0026#39;Password\u0026#39;placeHolder:\u0026#39;Enter basic authentication password\u0026#39;defaultValue:\u0026#39;\u0026#39;required:truebindable:trueoutputProperties:- name:basicAuthHeadertype:labeltitle:BasicAuthenticationHeader  NodeJS  ---runtime:\u0026#34;nodejs\u0026#34;code:| var context = require(\u0026#34;./context.js\u0026#34;)varusername=context.getInput(\u0026#34;username\u0026#34;);;varpassword=context.getInput(\u0026#34;password\u0026#34;);;constbuff=Buffer.from(username+\u0026#39;:\u0026#39;+password,\u0026#39;utf-8\u0026#39;);constbase64=buff.toString(\u0026#39;base64\u0026#39;);context.setOutput(\u0026#34;basicAuthHeader\u0026#34;,base64);inputProperties:# Username input- name:\u0026#39;username\u0026#39;type:texttitle:\u0026#39;Username\u0026#39;placeHolder:\u0026#39;Enter basic authentication usename\u0026#39;required:truebindable:true# Password input- name:\u0026#39;password\u0026#39;type:passwordtitle:\u0026#39;Password\u0026#39;placeHolder:\u0026#39;Enter basic authentication password\u0026#39;defaultValue:\u0026#39;\u0026#39;required:truebindable:trueoutputProperties:- name:basicAuthHeadertype:labeltitle:BasicAuthenticationHeader   To use my new task in a Pipeline stage, I create a new Task, select Type Custom and select my Custom Integration and released version. This automatically creates an input form for the username and password input properties. Because I have set bindable: true for these properties, I can bind them to Pipeline variables, or Variables\n Using a Custom Integration in a Custom task  To access the output property basicAuthHeader later on in my REST task, I can access the task properties by using the Stage name, Task name, then output.properties.propertyName - e.g:\n${Authenticate.Create Auth Header.output.properties.basicAuthHeader}\nReference     How do I integrate my own build, test, and deploy tools with vRealize Automation Code Stream  "},{"id":8,"href":"/Configure/Projects/","title":"Projects","parent":"Configure","content":"A Project is where you combine resources, with users, to put all your Pipelines, variables etc. in Codestream, to share between the members of the project.\n"},{"id":9,"href":"/Configure/Endpoints/","title":"Endpoints","parent":"Configure","content":"Configuring unique and separate Endpoints across multiple platforms and isolated environments allows for the integration, automation, and management of a complete software delivery solution for the entire DevOps timeline from beginning to end.\nEndpoints allow VMware Cloud Services to connect to remote applications and data sources. Code Stream becomes the focal point in the DevOps release process as a single unifying platform integration tool, acting as the glue between established industry standard DevOps toolsets.\n"},{"id":10,"href":"/Configure/variables/","title":"Variables","parent":"Configure","content":"Variables are a great way to keep text, secrets etc. that you have to reuse, in your Pipelines, in one central place, to easily manage. It\u0026rsquo;s also a good practice, if you need to export your pipelines, to make sure, that sensetive information is not exported as well.\nCreate      Create variables  Type     Regular - Value is not hidden Secret - Value is hidden Restricted - Pipelines containing Restricted variables, can only be run by administrators  Project    Variables need to be attached to a project.\nNames    The name you use, when you reference the variable\nValue    The actual value of the variable\nDescription    The description of the value, to easely identify the variable and the use of it.\nUse    When using the variable, all you need to do, is to write ${var.NameOfVariable} where you want to use it.\nSo a variable with the name of mysecret will look like\n${var.mysecret} in your pipeline\n"},{"id":11,"href":"/Configure/","title":"Configure","parent":"","content":""},{"id":12,"href":"/Triggers/Gerrit/","title":"Gerrit","parent":"Triggers","content":""},{"id":13,"href":"/Triggers/Git/","title":"Git","parent":"Triggers","content":""},{"id":14,"href":"/Triggers/Docker/","title":"Docker","parent":"Triggers","content":""},{"id":15,"href":"/Triggers/","title":"Triggers","parent":"","content":"Triggers are a way for Code Stream to integrate with Docker, Gerrit, and Git lifecycles. Code Stream connects to the respective endpoint through a Webhook.\nA Webhook is configured by an administrator for a push or pull request event on the Triggers tab. Through the webhook, any code change events on the remote repository are received by the trigger in Code Stream.\nActivity for Docker, Gerrit, and Git triggers and their webhooks can also be observed on the Triggers tab.\n"},{"id":16,"href":"/","title":"","parent":"","content":"What is Code Stream?    Code Stream is a service provided as part of VMware vRealize Automation, either as SaaS through VMware Cloud Services or an on-premises deployment.\nCode Stream is a continuous integration and delivery (CI/CD) release pipeline tool that allows developers to model and automate the entire release process. It incorporates a release dashboard to keep track of all the various release KPIs and acts as the glue between all existing DevOps tools in the release process.\nCode Stream can help teams to deliver software and code changes faster, more reliably and with higher quality while reducing manual operations and operational risk traditionally associated with releases.\nCode Stream provides a customizable dashboards so that DevOps teams can measure their release KPIs and identify bottlenecks or problem areas in the release process.\nCode Stream can be extended using the Custom Integrations feature to interact with almost any 3rd party system that has an API or CLI.\nIf you want to find out more about vRealize Automation you can visit the official product site, view product features, or take a closer look at Code Stream. You can alse explore vRealize Automation Cloud with a free 45-day trial.\n"},{"id":17,"href":"/Configure/Endpoints/bamboo/","title":"Bamboo","parent":"Endpoints","content":"ggg\n"},{"id":18,"href":"/Pipelines/Tasks/bamboo/","title":"Bamboo","parent":"Tasks","content":""},{"id":19,"href":"/categories/","title":"Categories","parent":"","content":""},{"id":20,"href":"/Pipelines/Tasks/ci/","title":"CI","parent":"Tasks","content":"The CI task enables almost any action in your pipeline by pulling a specific Docker image from a registry endpoint, and deploying it to a Docker host. It then executes the configured script in the context of the running container.\nThe CI task runs using parameters configured in the Pipeline Workspace configuration, including the Container Image, Docker Registry, Docker Host, directory, cache, environment variables and CPU/Memory limits.\nInputs    "},{"id":21,"href":"/Pipelines/Tasks/condition/","title":"Condition","parent":"Tasks","content":""},{"id":22,"href":"/Pipelines/Tasks/custom/","title":"Custom","parent":"Tasks","content":""},{"id":23,"href":"/Configure/Endpoints/docker/","title":"Docker","parent":"Endpoints","content":"ggg\n"},{"id":24,"href":"/Configure/Endpoints/dockeregistry/","title":"Docker Registry","parent":"Endpoints","content":"ggg\n"},{"id":25,"href":"/Configure/Endpoints/email/","title":"Email","parent":"Endpoints","content":"ggg\n"},{"id":26,"href":"/Configure/Endpoints/gerrit/","title":"Gerrit","parent":"Endpoints","content":"ggg\n"},{"id":27,"href":"/Configure/Endpoints/git/","title":"Git","parent":"Endpoints","content":"ggg\n"},{"id":28,"href":"/Getting-Started/helloworld/","title":"Hello World","parent":"Getting Started","content":"My first pipeline\n"},{"id":29,"href":"/Configure/Endpoints/jenkins/","title":"Jenkins","parent":"Endpoints","content":"ggg\n"},{"id":30,"href":"/Configure/Endpoints/jira/","title":"Jira","parent":"Endpoints","content":"ggg\n"},{"id":31,"href":"/Configure/Endpoints/kubernetes/","title":"Kubernetes","parent":"Endpoints","content":"ggg\n"},{"id":32,"href":"/Pipelines/Tasks/kubernetes/","title":"Kubernetes","parent":"Tasks","content":""},{"id":33,"href":"/Pipelines/Tasks/pipeline/","title":"Pipeline","parent":"Tasks","content":"Nesting pipelines\u0026hellip;\n"},{"id":34,"href":"/Pipelines/Tasks/poll/","title":"Poll","parent":"Tasks","content":"Poll\n"},{"id":35,"href":"/Pipelines/Tasks/powershell/","title":"PowerShell","parent":"Tasks","content":""},{"id":36,"href":"/Getting-Started/publishing/","title":"Publishing Pipelines","parent":"Getting Started","content":"Code Stream Pipelines can be published to Service Broker with a Custom Form, allowing you to create a much more interactive user experiece.\n"},{"id":37,"href":"/Pipelines/Tasks/rest/","title":"REST","parent":"Tasks","content":""},{"id":38,"href":"/Pipelines/Tasks/ssh/","title":"SSH","parent":"Tasks","content":""},{"id":39,"href":"/tags/","title":"Tags","parent":"","content":""},{"id":40,"href":"/Configure/Endpoints/tfs/","title":"TFS","parent":"Endpoints","content":"ggg\n"},{"id":41,"href":"/Pipelines/Tasks/tfs/","title":"TFS","parent":"Tasks","content":""},{"id":42,"href":"/Pipelines/Tasks/useroperation/","title":"User Operation","parent":"Tasks","content":""},{"id":43,"href":"/Pipelines/Tasks/cloudtemplate/","title":"VMware Cloud Template","parent":"Tasks","content":"Hmmm\n"},{"id":44,"href":"/Pipelines/Tasks/vro/","title":"vRealize Orchestrator","parent":"Tasks","content":""},{"id":45,"href":"/Configure/Endpoints/vro/","title":"vRealize Orchestrator (vRO)","parent":"Endpoints","content":"ggg\n"}]